import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import speech_recognition as sr
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import BayesianRidge
from xgboost import XGBRegressor
from sklearn.metrics import r2_score
from sklearn.preprocessing import MinMaxScaler

# ğŸŒ Page Config
st.set_page_config(page_title="AI Academic Dashboard", layout="wide")
st.title("ğŸ“ AI-Powered Academic Performance Dashboard")

# ğŸ“¥ Load Data
@st.cache_data
def load_data():
    df_mat = pd.read_csv("student-mat.csv", sep=';')
    df_por = pd.read_csv("student-por.csv", sep=';')
    return pd.concat([df_mat, df_por], axis=0).drop_duplicates().reset_index(drop=True)

df = load_data()

# ğŸ“Š Dataset Preview
st.subheader("1. Dataset Preview")
st.dataframe(df.head())
st.markdown(f"ğŸ“Œ Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns")

# ğŸ” Data Quality Insights
st.subheader("2. Data Quality Overview")
missing = df.isnull().mean().sort_values(ascending=False)
if missing.any():
    st.warning("âš ï¸ Missing Data Detected")
    st.dataframe(missing[missing > 0])
else:
    st.success("âœ… No missing values in the dataset.")
st.write("ğŸ” Unique Values per Feature:")
st.dataframe(df.nunique().sort_values(ascending=False))

# Section 3: Attribute Comparison with Final Grade (G3)
st.header("ğŸ“Š 3. Attribute Comparison with Final Grade (G3)")
st.markdown("""
This section shows the relationship between each feature and the final student grade (G3) using:
- A **Lollipop Chart** to visualize correlation values.
- A **Random Forest** model to extract and show feature importances.
""")

# ğŸ”§ Define selected_cols to avoid NameError
selected_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# 1. Lollipop Chart for Correlation with G3
st.subheader("ğŸ”— Correlation of Attributes with Final Grade (G3)")

# Calculate correlations
corr = df[selected_cols].corr()['G3'].drop('G3').sort_values()

# Plot Lollipop Chart
fig, ax = plt.subplots(figsize=(10, 6))
ax.hlines(y=corr.index, xmin=0, xmax=corr.values, color='skyblue', linewidth=2)
ax.plot(corr.values, corr.index, "o", color='blue')
ax.axvline(0, color='gray', linestyle='--', linewidth=1)
ax.set_xlabel("Correlation with Final Grade (G3)")
ax.set_title("Lollipop Chart: Feature Correlation with Final Grade (G3)")
st.pyplot(fig)

# 2. Feature Importance from Random Forest
st.subheader("ğŸŒ² Feature Importance from Random Forest Model")

# Prepare data
X = df[selected_cols].drop(columns=['G3'])
y = df['G3']

# Train model
model = RandomForestRegressor(random_state=42)
model.fit(X, y)

# Get feature importances
importances = pd.Series(model.feature_importances_, index=X.columns).sort_values()

# Plot Horizontal Bar Chart
fig2, ax2 = plt.subplots(figsize=(10, 6))
importances.plot(kind='barh', color='teal', ax=ax2)
ax2.set_xlabel("Importance Score")
ax2.set_title("Random Forest: Feature Importance for Final Grade (G3)")
st.pyplot(fig2)

# ğŸ§  Model Comparison
st.subheader("4. Model Accuracy Comparison")
features = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'absences', 'G1', 'G2']
X = df[features]
y = df['G3']
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

models = {
    "Random Forest": RandomForestRegressor(),
    "XGBoost": XGBRegressor(),
    "Bayesian Ridge": BayesianRidge()
}
scores = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    scores[name] = r2_score(y_test, preds)

st.write("ğŸ” **RÂ² Scores:**")
st.json(scores)
best_model = max(scores, key=scores.get)
st.success(f"âœ… Best Model: {best_model} (RÂ²: {scores[best_model]:.2f})")

# ğŸ” Feature Importance for Random Forest
if best_model == "Random Forest":
    st.subheader("ğŸ“Š Feature Importance (Random Forest)")
    importance_df = pd.DataFrame({
        "Feature": features,
        "Importance": models[best_model].feature_importances_
    }).sort_values(by="Importance", ascending=False)
    st.bar_chart(importance_df.set_index("Feature"))

# ğŸ“Œ AI-Driven Socioeconomic Recommendations
st.subheader("5. AI-Driven Recommendations for Academic Support")

recommendations = []

if corr['Medu'] > 0.2 or corr['Fedu'] > 0.2:
    recommendations.append("ğŸ“š **Parental Education**: Students with better-educated parents (especially mothers) tend to perform better. Promote adult education and family engagement programs.")

if corr['failures'] < -0.3:
    recommendations.append("â±ï¸ **Failures**: Past failures significantly lower future academic performance. Implement early warning systems, mentoring, and after-school tutoring.")

if corr['studytime'] > 0.2:
    recommendations.append("ğŸ“– **Study Time**: More time spent studying correlates with better grades. Encourage structured study routines and productivity workshops.")

if corr['absences'] < -0.2:
    recommendations.append("ğŸ« **Absenteeism**: Higher absenteeism negatively impacts performance. Consider attendance incentives and parental counseling.")

if corr['traveltime'] < -0.1:
    recommendations.append("ğŸšŒ **Travel Time**: Long commute times reduce study opportunities. Suggest community learning centers or hybrid/online classes.")

if not recommendations:
    st.warning("No strong actionable insights found. Consider checking more features or using feature engineering.")
else:
    for rec in recommendations:
        st.info(rec)

# ğŸ“¥ Downloadable Recommendation Report
st.subheader("6. Downloadable Report")
if st.button("ğŸ“¤ Download AI Recommendations"):
    rec_text = "\n\n".join(recommendations)
    st.download_button("ğŸ“„ Download", rec_text, file_name="ai_recommendations.txt")

# ğŸ¯ Predict Final Grade + Recommend Learning Path
st.subheader("7. Predict Final Grade & Get Personalized Learning Path")

with st.form("combined_prediction_form"):
    st.markdown("ğŸ“Œ Enter student academic and socio-economic details:")
    age = st.slider("Age", 15, 22, 17)
    Medu = st.selectbox("Mother's Education Level", options=[0, 1, 2, 3, 4],
                    format_func=lambda x: {
                        0: "0 - None",
                        1: "1 - Primary (up to 4th grade)",
                        2: "2 - 5th to 9th grade",
                        3: "3 - Secondary (High School)",
                        4: "4 - Higher (University)"
                    }[x])

    Fedu = st.selectbox("Father's Education Level", options=[0, 1, 2, 3, 4],
                    format_func=lambda x: {
                        0: "0 - None",
                        1: "1 - Primary (up to 4th grade)",
                        2: "2 - 5th to 9th grade",
                        3: "3 - Secondary (High School)",
                        4: "4 - Higher (University)"
                    }[x])
    traveltime = st.slider("Travel Time (1=short <15min - 4=long >1hr)", 1, 4, 1)
    studytime = st.slider("Weekly Study Time (1=<2hrs - 4=>10hrs)", 1, 4, 2)
    failures = st.slider("Past Class Failures", 0, 4, 0)
    absences = st.slider("Total Absences", 0, 100, 5)
    G1 = st.slider("First Period Grade (G1)", 0, 20, 10)
    G2 = st.slider("Second Period Grade (G2)", 0, 20, 10)

    submitted = st.form_submit_button("ğŸ“ Predict & Recommend")

if submitted:
    input_data = pd.DataFrame([[age, Medu, Fedu, traveltime, studytime, failures, absences, G1, G2]], columns=features)
    input_scaled = scaler.transform(input_data)
    G3_pred = models[best_model].predict(input_scaled)[0]

    st.success(f"ğŸ“ Predicted Final Grade (G3): {G3_pred:.2f}")

    # ğŸ“Œ Personalized Academic Recommendations
    recommendations = []

    if G3_pred < 10:
        recommendations.append("ğŸ”´ **At-Risk Student**: Personalized tutoring sessions needed with focus on weak concepts from G1 & G2.")
        if failures > 0:
            recommendations.append("âŒ Prior failures detected. Recommend academic counseling and regular progress tracking.")
        if studytime <= 2:
            recommendations.append("â±ï¸ Study time is low. Suggest time management coaching and digital learning planners.")
        if absences > 10:
            recommendations.append("ğŸ« High absenteeism. Engage with guardians and consider blended/remote learning models.")

    elif G3_pred < 14:
        recommendations.append("ğŸŸ¡ **Average Performer**: Recommend structured self-paced modules and performance goals.")
        if studytime <= 2:
            recommendations.append("ğŸ“˜ Boost study hours using techniques like Pomodoro and spaced repetition.")
        if absences > 5:
            recommendations.append("ğŸ•’ Reduce missed classes by sending automated alerts and reminders.")

    else:
        recommendations.append("ğŸŸ¢ **High Performer**: Recommend advanced learning paths or gifted programs.")
        if studytime > 3:
            recommendations.append("ğŸš€ Encourage participation in competitions or online MOOCs (Coursera, edX).")

    st.markdown("### ğŸ§‘â€ğŸ« Recommended Actions:")
    for rec in recommendations:
        st.info(rec)

    # ğŸ“š AI-Powered Learning Resource Recommender
    st.markdown("### ğŸ“š Tailored Learning Resources")

    if G3_pred < 10:
        st.markdown("- [ğŸ¥ How to Study Effectively â€“ Science-Based Tips (YouTube)](https://youtu.be/p60rN9JEapg)")
        st.markdown("- [â±ï¸ Pomodoro Timer Web Tool](https://pomofocus.io/)")
        st.markdown("- [ğŸ“˜ Time Management Course â€“ Coursera](https://www.coursera.org/learn/work-smarter-not-harder)")
        st.markdown("- [ğŸ“— Khan Academy â€“ Foundational Skills](https://www.khanacademy.org)")
        st.markdown("- [ğŸ§  Motivation for Students â€“ TEDx Talk](https://youtu.be/O96fE1E-rf8)")

    elif G3_pred < 14:
        st.markdown("- [ğŸ“ Study Skills for High School & College â€“ YouTube](https://youtu.be/CPxSzxylRCI)")
        st.markdown("- [ğŸ“ˆ Focus & Productivity Guide â€“ Todoist Blog](https://blog.todoist.com/productivity-methods/)")
        st.markdown("- [ğŸ“š Self-Paced Learning: Study Smarter](https://www.opencollege.info/self-paced-learning/)")

    else:
        st.markdown("- [ğŸ† Advanced MOOC: edX â€“ Academic Excellence Courses](https://www.edx.org/learn/study-skills)")
        st.markdown("- [ğŸ–ï¸ Olympiad/Competition Preparation â€“ Learn More](https://artofproblemsolving.com/)")
        st.markdown("- [ğŸš€ Research Basics for Students â€“ Google Scholar Guide](https://scholar.google.com/)")


# ğŸ’¬ Chatbot
st.subheader("8. Chat bot")
import streamlit as st
import speech_recognition as sr
import pyttsx3
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# ----------------------
# Load Model and Tokenizer
# ----------------------
@st.cache_resource
def load_model():
    model_name = "distilgpt2"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_model()

# ----------------------
# Bot Response Function
# ----------------------
def generate_response(prompt):
    inputs = tokenizer.encode(prompt, return_tensors="pt")
    outputs = model.generate(inputs, max_length=200, pad_token_id=tokenizer.eos_token_id)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ----------------------
# Text-to-Speech
# ----------------------
def speak_text(text):
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

# ----------------------
# Speech-to-Text
# ----------------------
def listen_to_voice():
    recognizer = sr.Recognizer()
    mic = sr.Microphone()
    with mic as source:
        st.info("ğŸ¤ Listening...")
        audio = recognizer.listen(source)
    try:
        text = recognizer.recognize_google(audio)
        st.success(f"âœ… You said: {text}")
        return text
    except sr.UnknownValueError:
        st.error("âŒ Could not understand audio.")
    except sr.RequestError:
        st.error("âŒ Speech recognition service unavailable.")
    return ""

# ----------------------
# Session State
# ----------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ----------------------
# Streamlit UI
# ----------------------
st.set_page_config(page_title="Local AI Chatbot", layout="centered")
st.title("ğŸ¤– Local AI Chatbot with Voice")

st.markdown("""
    <style>
    .chatbox {
        padding: 12px;
        margin-bottom: 10px;
        border-radius: 12px;
    }
    .user-msg {
        background-color: #d1e7dd;
        text-align: right;
    }
    .bot-msg {
        background-color: #f8d7da;
        text-align: left;
    }
    </style>
""", unsafe_allow_html=True)

# ----------------------
# Voice Button
# ----------------------
if st.button("ğŸ™ï¸ Talk to the Bot"):
    user_input = listen_to_voice()
    if user_input:
        bot_response = generate_response(user_input)
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        st.session_state.chat_history.append({"role": "bot", "content": bot_response})
        speak_text(bot_response)

# ----------------------
# Chat Display
# ----------------------
st.markdown("### ğŸ’¬ Chat History")
for msg in st.session_state.chat_history:
    cls = "user-msg" if msg["role"] == "user" else "bot-msg"
    st.markdown(f'<div class="chatbox {cls}">{msg["content"]}</div>', unsafe_allow_html=True)

# ----------------------
# Manual Text Input
# ----------------------
user_text = st.text_input("Type a message and press Enter:")
if user_text:
    bot_response = generate_response(user_text)
    st.session_state.chat_history.append({"role": "user", "content": user_text})
    st.session_state.chat_history.append({"role": "bot", "content": bot_response})
    speak_text(bot_response)
    st.experimental_rerun()
